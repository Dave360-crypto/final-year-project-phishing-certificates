{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note collection_day refers to day of most recent attempt at collecting certificate, but such attempt may not have yielded a certificate anyways. Actual count of certificates is done elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OpenSSL import crypto\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"url_datasets/phishtank-\"\n",
    "days = ['16-04','18-04','19-04','20-04','21-04','22-04','23-04','24-04','30-04','01-05','03-05','04-05','05-05','07-05','08-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for day in days:\n",
    "    path = base_path + day + '.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10170\n",
      "706\n",
      "426\n",
      "361\n",
      "382\n",
      "423\n",
      "734\n",
      "55\n",
      "1453\n",
      "437\n",
      "738\n",
      "465\n",
      "741\n",
      "727\n"
     ]
    }
   ],
   "source": [
    "distinct_urls = []\n",
    "distinct_url_dfs = []\n",
    "for i, df in enumerate(dfs):\n",
    "    if i > 0:\n",
    "        my_urls = df['url']\n",
    "        prev_urls = dfs[i-1]['url']\n",
    "        new_urls = list(set(my_urls)-set(prev_urls))\n",
    "    else:\n",
    "        new_urls = df['url']\n",
    "    print(len(new_urls))\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['url'] = new_urls\n",
    "    new_df['day_collected'] = [days[i] for _ in new_urls]\n",
    "    distinct_url_dfs.append(new_df)\n",
    "    \n",
    "    distinct_urls.append(new_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>day_collected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://microsoftonlinefaxlinkvonage.weebly.com/</td>\n",
       "      <td>16-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://bunblkol.com/</td>\n",
       "      <td>16-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://acibadem.weebly.com/</td>\n",
       "      <td>16-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://ingdericto.temp.swtest.ru/ing/</td>\n",
       "      <td>16-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://geolp.weebly.com/</td>\n",
       "      <td>16-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>https://amaeoirugleriwserwermbvfdzv.life/pc</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>https://economy.freedynamicdns.net/</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>http://p7.continuewide.work/apmix</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>http://domamaxion.com/DONE/amazkn/mazon/3db5c/...</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>https://blog.fatimaesportes.com.br/new/notice.php</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17818 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url day_collected\n",
       "0     https://microsoftonlinefaxlinkvonage.weebly.com/         16-04\n",
       "1                                 http://bunblkol.com/         16-04\n",
       "2                         https://acibadem.weebly.com/         16-04\n",
       "3                http://ingdericto.temp.swtest.ru/ing/         16-04\n",
       "4                            https://geolp.weebly.com/         16-04\n",
       "..                                                 ...           ...\n",
       "722        https://amaeoirugleriwserwermbvfdzv.life/pc         07-05\n",
       "723                https://economy.freedynamicdns.net/         07-05\n",
       "724                  http://p7.continuewide.work/apmix         07-05\n",
       "725  http://domamaxion.com/DONE/amazkn/mazon/3db5c/...         07-05\n",
       "726  https://blog.fatimaesportes.com.br/new/notice.php         07-05\n",
       "\n",
       "[17818 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_distinct_df = pd.concat(distinct_url_dfs)\n",
    "final_distinct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_distinct_df.to_csv('url_datasets/distinct_phish_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17817"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(final_distinct_df['url']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reorganise all phish data in one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cert collection might have succeded on previous day and failed on next, there were mistakes early on where certificates were recollected. Newest certificate for a url will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in enumerate(days):\n",
    "    data_path = 'phish_data-'+d+'/'\n",
    "    target_path = 'phish_data/'\n",
    "    curr_urls = dfs[i]['url']\n",
    "    \n",
    "    for url in curr_urls:\n",
    "        try:\n",
    "            url = url.split(\"/\")[2]\n",
    "            f = open(data_path+url)\n",
    "            line = f.readline()\n",
    "            if line != '':\n",
    "                f.close()\n",
    "                shutil.move(data_path+url, target_path+url)\n",
    "        except:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort out benign collection tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even benign collection fails sometimes, so the 11000 failures were reattempted on another day, need to track which day they were collected though for certain statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_days = ['04-05','07-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"url_datasets/majestic_million.csv\"\n",
    "df = pd.read_csv(path)\n",
    "urls = df['Domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = 50000\n",
    "urls = urls[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_i = np.zeros(how_many,dtype=bool)\n",
    "failures = []\n",
    "f = open('benign_urls-refetch.txt')\n",
    "line = f.readline()[:-1]\n",
    "while line != '':\n",
    "    failures.append(line)\n",
    "    line = f.readline()[:-1]\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(how_many):\n",
    "    if urls[i] in failures:\n",
    "        failures_i[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 38010, True: 11990})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(failures_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_tags = [benign_days[1] if failures_i[i] else benign_days[0] for i in range(how_many)]\n",
    "\n",
    "benign_df = pd.DataFrame()\n",
    "benign_df['url'] = urls\n",
    "benign_df['day_collected'] = day_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>day_collected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google.com</td>\n",
       "      <td>04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook.com</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instagram.com</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>ssoloans.com</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>sildenafilyes.com</td>\n",
       "      <td>04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>pillmy.com</td>\n",
       "      <td>04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>bradshawfoundation.com</td>\n",
       "      <td>07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>rockhealth.com</td>\n",
       "      <td>04-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          url day_collected\n",
       "0                  google.com         04-05\n",
       "1                facebook.com         07-05\n",
       "2                 youtube.com         04-05\n",
       "3                 twitter.com         04-05\n",
       "4               instagram.com         07-05\n",
       "...                       ...           ...\n",
       "49995            ssoloans.com         07-05\n",
       "49996       sildenafilyes.com         04-05\n",
       "49997              pillmy.com         04-05\n",
       "49998  bradshawfoundation.com         07-05\n",
       "49999          rockhealth.com         04-05\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_df.to_csv('url_datasets/distinct_benign_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
